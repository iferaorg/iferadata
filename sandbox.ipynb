{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ifera\n",
    "import torch\n",
    "\n",
    "importlib.reload(ifera)\n",
    "\n",
    "cm = ifera.ConfigManager()\n",
    "# instrument = config.get_config('IBKR', 'NIY:1m')\n",
    "\n",
    "# ifera.check_s3_file_exists(S3_BUCKET, ifera.make_s3_key(instrument, True))\n",
    "\n",
    "# df_raw = ifera.load_data(raw=True, instrument=instrument, zipfile=True)\n",
    "\n",
    "# df = ifera.load_data(raw=False, instrument=instrument, zipfile=True, reset=True)\n",
    "\n",
    "# instrument = config.get_config('IBKR', 'HE:1m')\n",
    "# t_old = ifera.load_data_tensor(instrument=instrument, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "# t_new = ifera.load_data_tensor(instrument=instrument, reset=True, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "\n",
    "# t_new.isclose(t_old).all()\n",
    "\n",
    "# instrument = config.get_config('IBKR', 'NN:1m')\n",
    "# t_nn = ifera.load_data_tensor(instrument=instrument, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "\n",
    "iconfig = cm.get_config('IBKR', 'GF:1m')\n",
    "#t = ifera.load_data_tensor(instrument=instrument, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "\n",
    "instrument2 = cm.get_config('IBKR', 'GF:1m')\n",
    "instrument3 = iconfig.model_copy()\n",
    "\n",
    "iconfig.__eq__(instrument2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "all_steps = pd.timedelta_range(start=pd.Timedelta(0), end=pd.Timedelta(days=1), freq=iconfig.time_step)\n",
    "# Filter out steps that are greater than or equal to instrument end time\n",
    "all_steps[all_steps < iconfig.trading_end - iconfig.trading_start][-1]\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ifera\n",
    "\n",
    "cm = ifera.ConfigManager()\n",
    "brokerConfig = cm.get_broker_config('IBKR')\n",
    "\n",
    "for key, baseConfig in cm.instruments_data.items():\n",
    "    if baseConfig['symbol'] in brokerConfig.instruments.keys() and baseConfig['type'] == 'futures':\n",
    "        iconfig = cm.get_config('IBKR', key)\n",
    "        t = ifera.load_data_tensor(instrument=iconfig, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata2 = ifera.InstrumentData(iconfig, device=torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ifera.MarketSimulatorIntraday(idata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ifera\n",
    "device=torch.device('cuda:0')\n",
    "\n",
    "cm = ifera.ConfigManager()\n",
    "iconfig = cm.get_config('IBKR', 'CL:1m')\n",
    "dm = ifera.DataManager()\n",
    "idata2 = dm.get_instrument_data(iconfig, device=device)\n",
    "ms = ifera.MarketSimulatorIntraday(idata2)\n",
    "t = (iconfig.liquid_start - iconfig.trading_start).total_seconds() // iconfig.time_step.total_seconds()\n",
    "\n",
    "date_idx = torch.arange(0, idata2.data.shape[1], dtype=torch.int32, device=device)\n",
    "time_idx = torch.full_like(date_idx, t, dtype=torch.int32, device=device)\n",
    "position = torch.zeros_like(date_idx, dtype=torch.int32, device=device)\n",
    "action = torch.full_like(date_idx, 1, dtype=torch.int32, device=device)\n",
    "stop_loss = torch.full_like(date_idx, torch.nan, dtype=torch.float32, device=device)\n",
    "\n",
    "%timeit ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "#idata.data[0, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "\n",
    "parent_data = idata2.data\n",
    "multiplier = 120\n",
    "parent_steps = parent_data.shape[1]\n",
    "padding = parent_steps - parent_steps // multiplier * multiplier\n",
    "padding_data = torch.zeros((parent_data.shape[0], parent_data.shape[2]), dtype=parent_data.dtype, device=parent_data.device)\n",
    "padding_data[:, 0:4] = parent_data[:, -1, 3, None]  # Open, High, Low, Close <- Last Close\n",
    "padding_data = repeat(padding_data, \"d c -> d g c\", g=padding)\n",
    "parent_data = torch.cat([parent_data, padding_data], dim=1)\n",
    "rearrange(parent_data, \"d (g n) c -> d g c n\", n=120).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata2.instrument.contract_multiplier * (1051.0 - idata2.instrument.min_slippage - 1051.0) - 2.25, idata2.instrument.min_slippage * idata2.instrument.contract_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "iconfig = cm.get_config('IBKR', 'CL:1m')\n",
    "t = ifera.load_data_tensor(instrument=iconfig, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "t[-60 * 8 + 30], dt.date.fromordinal(int(t[-60 * 8 + 30, 0].item())), dt.timedelta(seconds=t[-60 * 8 + 30, 1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ifera.load_data(raw=True, instrument=iconfig, zipfile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[dt.datetime(2025, 1, 13, 9, 30)]\n",
    "import pandas as pd\n",
    "\n",
    "iconfig = cm.get_config('IBKR', 'NIY:1m')\n",
    "\n",
    "df = ifera.load_data(raw=True, instrument=iconfig, zipfile=True)\n",
    "t = ifera.load_data_tensor(instrument=iconfig, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "\n",
    "print(df.loc[dt.datetime(2025, 1, 10, 9, 30)])\n",
    "idx = -60 * 8 + 30 - 23 * 60 \n",
    "s = dt.timedelta(seconds=t[idx, 1].item()).seconds\n",
    "f\"Date: {dt.date.fromordinal(int(t[idx, 0].item()))}, Time: {s//3600}:{(s%3600)//60}:{s%60:02d}, Open: {t[idx, 4].item():.2f}, High: {t[idx, 5].item():.2f}, Low: {t[idx, 6].item():.2f}, Close: {t[idx, 7].item():.2f}, Volume: {t[idx, 8].item():.0f}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n",
    "df.loc[dt.datetime(2025, 1, 10, 9, 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "response = s3.list_objects(Bucket=\"kibotdata\", Prefix='futures/1m/')\n",
    "for obj in sorted(response.get('Contents', []), key=lambda x: x['Size'], reverse=True):\n",
    "    print(obj['Key'], obj['Size'] // 1024**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ifera\n",
    "\n",
    "cm = ifera.ConfigManager()\n",
    "broker = cm.get_broker_config('IBKR')\n",
    "\n",
    "for iconfig in broker.instruments:\n",
    "    iconfig = cm.get_config('IBKR', f\"{iconfig}:1m\")\n",
    "    df = ifera.load_data(raw=False, instrument=iconfig, zipfile=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ifera\n",
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "cm = ifera.ConfigManager()\n",
    "broker = cm.get_broker_config('IBKR')\n",
    "\n",
    "for key in cm.instruments_data.keys():\n",
    "    base_inst = cm.get_base_instrument_config(key)\n",
    "    if base_inst.symbol not in broker.instruments:\n",
    "        continue\n",
    "    iconfig = cm.get_config('IBKR', key)\n",
    "    t = ifera.load_data_tensor(instrument=iconfig, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "    t = rearrange(t, '(d t) c -> d t c', t = iconfig.total_steps)\n",
    "    print(iconfig.symbol, t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = t[:, :, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ifera\n",
    "channels = {\"Open\":0, \"High\":1, \"Low\":2, \"Close\":3, \"Volume\":4}\n",
    "\n",
    "# Relative True Range: max(high, prev_close) / min(low, prev_close), and simple high/low ratio for the first bar\n",
    "rtr = torch.zeros_like(data[:, :, channels[\"Close\"]])\n",
    "rtr[:, 0] = data[:, 0, channels[\"High\"]] / data[:, 0, channels[\"Low\"]] - 1.0\n",
    "rtr[:, 1:] = torch.max(data[:, 1:, channels[\"High\"]], data[:, :-1, channels[\"Close\"]]) / torch.min(data[:, 1:, channels[\"Low\"]], data[:, :-1, channels[\"Close\"]]) - 1.0\n",
    "\n",
    "# Where volume is zero set rtr to be the same as the previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "\n",
    "channels = {\"Open\":0, \"High\":1, \"Low\":2, \"Close\":3, \"Volume\":4}\n",
    "\n",
    "volume = data[:, :, channels[\"Volume\"]].to(torch.int32)\n",
    "\n",
    "# Find first non-zero volume each day\n",
    "first_non_zero = torch.argmax((volume > 0).to(torch.int8), dim=1)\n",
    "\n",
    "rtr = torch.zeros_like(data[:, :, channels[\"Close\"]])\n",
    "rtr[:, first_non_zero] = data[:, first_non_zero, channels[\"High\"]] / data[:, first_non_zero, channels[\"Low\"]] - 1.0\n",
    "\n",
    "mask = volume != 0\n",
    "vdata = data[mask, :]\n",
    "vrtr = rtr[mask]\n",
    "\n",
    "raw_rtr = torch.max(vdata[1:, channels[\"High\"]], vdata[:-1, channels[\"Close\"]]) / torch.min(vdata[1:, channels[\"Low\"]], vdata[:-1, channels[\"Close\"]]) - 1.0\n",
    "vrtr[1:] = torch.where(vrtr[1:] == 0, raw_rtr, vrtr[1:])\n",
    "\n",
    "artr = ifera.ema_slow(vrtr, 1/14)\n",
    "\n",
    "artr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]], dtype=torch.float32)\n",
    "window = 3\n",
    "\n",
    "n = min(t.shape[-1], window)\n",
    "tail = t.unfold(dimension=-1, size=n, step=1).mean(dim=-1)\n",
    "\n",
    "head_nom = torch.cumsum(t[..., :n-1], dim=-1)\n",
    "head_denom = torch.arange(1, n, device=t.device, dtype=t.dtype)\n",
    "head = head_nom / head_denom\n",
    "\n",
    "sma = torch.cat([head, tail], dim=-1)\n",
    "sma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ifera\n",
    "from einops import rearrange\n",
    "\n",
    "cm = ifera.ConfigManager()\n",
    "iconfig = cm.get_config(\"IBKR\", \"CL:1m\")\n",
    "\n",
    "dm = ifera.DataManager()\n",
    "idata = dm.get_instrument_data(iconfig)\n",
    "\n",
    "batch_size = idata.data.shape[0]-250\n",
    "\n",
    "openPolicy = ifera.AlwaysOpenPolicy(direction=1)\n",
    "initStopPolicy = ifera.InitialArtrStopLossPolicy(\n",
    "    instrument_data=idata, atr_multiple=3.0\n",
    ")\n",
    "maintenancePolicy = ifera.ScaledArtrMaintenancePolicy(\n",
    "    instrument_data=idata,\n",
    "    stages=[\"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"],\n",
    "    atr_multiple=3.0,\n",
    "    wait_for_breakeven=False,\n",
    "    minimum_improvement=0.0,\n",
    ")\n",
    "\n",
    "tradingPolicy = ifera.TradingPolicy(\n",
    "    instrument_data=idata,\n",
    "    open_position_policy=openPolicy,\n",
    "    initial_stop_loss_policy=initStopPolicy,\n",
    "    position_maintenance_policy=maintenancePolicy,\n",
    ")\n",
    "\n",
    "#tradingPolicy = torch.compile(tradingPolicy)\n",
    "\n",
    "ms = ifera.MarketSimulatorIntraday(instrument_data=idata)\n",
    "\n",
    "t = (iconfig.liquid_start - iconfig.trading_start).total_seconds() // iconfig.time_step.total_seconds() - 1\n",
    "\n",
    "date_idx = torch.arange(0, batch_size, dtype=torch.int32, device=idata.device)\n",
    "time_idx = torch.full_like(date_idx, t, dtype=torch.int32, device=idata.device)\n",
    "position = torch.zeros_like(date_idx, dtype=torch.int32, device=idata.device)\n",
    "prev_stop_loss = torch.full_like(date_idx, torch.nan, dtype=torch.float32, device=idata.device)\n",
    "execution_price = torch.full_like(date_idx, torch.nan, dtype=torch.float32, device=idata.device)\n",
    "\n",
    "total_profit = torch.zeros_like(date_idx, dtype=torch.float32, device=idata.device)\n",
    "\n",
    "# Open position\n",
    "action, stop_loss = tradingPolicy(date_idx, time_idx, position, prev_stop_loss, execution_price)\n",
    "time_idx += 1\n",
    "profit, position, execution_price, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "position = position.clone()\n",
    "total_profit += profit\n",
    "\n",
    "while (position != 0).any():\n",
    "    prev_stop_loss = stop_loss.clone()\n",
    "    action, stop_loss = tradingPolicy(date_idx, time_idx, position, prev_stop_loss, execution_price)\n",
    "    date_idx, time_idx = idata.get_next_indices(date_idx, time_idx)\n",
    "    action = torch.where((date_idx == idata.data.shape[0] - 1) & (time_idx == idata.data.shape[1] - 1), -position, 0)\n",
    "    profit, position, execution_price, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "    position = position.clone()\n",
    "    total_profit += profit\n",
    "\n",
    "max_idx = total_profit.argmax()\n",
    "print(f\"Max index: {max_idx}, Total profit: {total_profit[max_idx].item():.4f}, date_idx: {date_idx[max_idx].item()}, time_idx: {time_idx[max_idx].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "t = torch.arange(0, 10, dtype=torch.int32)\n",
    "mask = torch.zeros_like(t, dtype=torch.bool)\n",
    "\n",
    "t, mask, torch.cat((t[mask], torch.tensor([np.iinfo(np.int32).max], dtype=torch.int32)), dim=0).min().item(), t[t< 5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ifera\n",
    "import torch\n",
    "\n",
    "instrument = ifera.ConfigManager().get_base_instrument_config(\"TN:1m\")\n",
    "url = ifera.make_instrument_url(ifera.Scheme.FILE, ifera.Source.PROCESSED, instrument)\n",
    "# print(url)\n",
    "\n",
    "#t = ifera.load_data_tensor(instrument=instrument, reset=False, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "fm = ifera.FileManager()\n",
    "fm.refresh_file(\"adasd\")\n",
    "\n",
    "# t.shape\n",
    "# print(ifera.FileOperations.exists(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ifera\n",
    "import torch\n",
    "\n",
    "dm = ifera.DataManager()\n",
    "cm = ifera.ConfigManager()\n",
    "#parent_instrument = cm.get_base_instrument_config(\"TN\", \"1m\")\n",
    "#instrument = cm.create_derived_base_config(parent_instrument, \"5m\")\n",
    "instrument = cm.get_base_instrument_config(\"TN\", \"30m\")\n",
    "device=torch.device(\"cuda:0\")\n",
    "\n",
    "idata = dm.get_instrument_data(instrument_config=instrument, dtype=torch.float32, device=device)\n",
    "\n",
    "idata.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ifera\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "dm = ifera.DataManager()\n",
    "cm = ifera.ConfigManager()\n",
    "instrument = cm.get_base_instrument_config(\"TN:1m\")\n",
    "idata = dm.get_instrument_data(instrument_config=instrument, dtype=torch.float32, device=torch.device(\"cuda:0\"))\n",
    "print(idata.data.shape)\n",
    "ms = ifera.MarketSimulatorIntraday(instrument_data=idata, broker_name=\"IBKR\")\n",
    "\n",
    "date_idx = torch.zeros(idata.data.shape[0], dtype=torch.int32, device=idata.device)\n",
    "time_idx = torch.full_like(date_idx, 0, dtype=torch.int32, device=idata.device)\n",
    "position = torch.full_like(date_idx, 1, dtype=torch.int32, device=idata.device)\n",
    "action = torch.full_like(date_idx, 0, dtype=torch.int32, device=idata.device)\n",
    "stop_loss = torch.full_like(date_idx, torch.nan, dtype=torch.float32, device=idata.device)\n",
    "\n",
    "def run_market_simulation(ms, idata):\n",
    "    date_idx = torch.randint(0, idata.data.shape[0] - total_days - 2, (idata.data.shape[0],), dtype=torch.int32, device=idata.device)\n",
    "    time_idx = torch.randint_like(date_idx, 0, idata.data.shape[1] - 1, dtype=torch.int32, device=idata.device)\n",
    "    position = torch.full_like(date_idx, 0, dtype=torch.int32, device=idata.device)\n",
    "    action = torch.full_like(date_idx, 1, dtype=torch.int32, device=idata.device)\n",
    "    stop_loss = torch.full_like(date_idx, torch.nan, dtype=torch.float32, device=idata.device)\n",
    "    total_profit = torch.zeros_like(date_idx, dtype=torch.float32, device=idata.device)\n",
    "    steps = torch.tensor(0, dtype=torch.int32, device=idata.device)\n",
    "    max_days = 4\n",
    "\n",
    "    while date_idx[0] < max_days or time_idx[0] < idata.data.shape[1] - 1:\n",
    "        profit, new_position, _, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "        position = new_position.clone()\n",
    "        action = torch.zeros_like(date_idx, dtype=torch.int32, device=idata.device)\n",
    "        date_idx, time_idx = idata.get_next_indices(date_idx, time_idx)\n",
    "        total_profit += profit\n",
    "        steps += 1\n",
    "    \n",
    "    return total_profit, steps\n",
    "\n",
    "def run_market_simulation_tqdm(ms, idata):\n",
    "    total_days = 5\n",
    "    date_idx = torch.randint(0, idata.data.shape[0] - total_days - 2, (idata.data.shape[0],), dtype=torch.int32, device=idata.device)\n",
    "    time_idx = torch.randint_like(date_idx, 0, idata.data.shape[1] - 1, dtype=torch.int32, device=idata.device)\n",
    "    position = torch.full_like(date_idx, 0, dtype=torch.int32, device=idata.device)\n",
    "    action = torch.full_like(date_idx, 1, dtype=torch.int32, device=idata.device)\n",
    "    stop_loss = torch.full_like(date_idx, torch.nan, dtype=torch.float32, device=idata.device)\n",
    "    total_profit = torch.zeros_like(date_idx, dtype=torch.float32, device=idata.device)\n",
    "    steps = torch.tensor(0, dtype=torch.int32, device=idata.device)\n",
    "    total_steps = total_days * idata.data.shape[1]\n",
    "    pbar = tqdm(total=total_steps, desc=\"Market Simulation\", unit=\"step\", leave=False)\n",
    "\n",
    "    while steps < total_steps:\n",
    "        profit, new_position, _, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "        total_profit += profit\n",
    "        position = new_position.clone()\n",
    "        action = torch.where(position == 0, action, 0)\n",
    "        date_idx, time_idx = idata.get_next_indices(date_idx, time_idx)\n",
    "        steps += 1\n",
    "        pbar.update(1)\n",
    "    \n",
    "    return total_profit, steps\n",
    "\n",
    "\n",
    "run_market_simulation_compiled = torch.compile(run_market_simulation)\n",
    "run_market_simulation_tqdm_compiled = torch.compile(run_market_simulation_tqdm)\n",
    "\n",
    "# Warmup calculate_step\n",
    "profit, _, _, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "profit, _, _, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "profit, _, _, _ = ms.calculate_step(date_idx, time_idx, position, action, stop_loss)\n",
    "\n",
    "# Run the market simulation\n",
    "start_t = time.time()\n",
    "total_profit, steps = run_market_simulation(ms, idata)\n",
    "print(f\"Time taken: {time.time() - start_t:.2f} seconds\")\n",
    "\n",
    "# Warmup the compiled function\n",
    "total_profit, steps = run_market_simulation_compiled(ms, idata)\n",
    "total_profit, steps = run_market_simulation_compiled(ms, idata)\n",
    "start_t = time.time()\n",
    "total_profit, steps = run_market_simulation_compiled(ms, idata)\n",
    "print(f\"Time taken: {time.time() - start_t:.2f} seconds\")\n",
    "\n",
    "# Run uncompiled function with tqdm\n",
    "start_t = time.time()\n",
    "total_profit, steps = run_market_simulation_tqdm(ms, idata)\n",
    "print(f\"Time taken: {time.time() - start_t:.2f} seconds\")\n",
    "\n",
    "# Warmup the compiled function with tqdm\n",
    "total_profit, steps = run_market_simulation_tqdm_compiled(ms, idata)\n",
    "total_profit, steps = run_market_simulation_tqdm_compiled(ms, idata)\n",
    "start_t = time.time()\n",
    "total_profit, steps = run_market_simulation_tqdm_compiled(ms, idata)\n",
    "print(f\"Time taken: {time.time() - start_t:.2f} seconds\")\n",
    "print(total_profit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore.exceptions\n",
    "\n",
    "client = boto3.client(\"s3\")\n",
    "bucket = \"ifera-marketdata\"\n",
    "\n",
    "try:\n",
    "    client.head_object(Bucket=bucket, Key='asdasdasd')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    print(e.response['Error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "timedelta(hours=16,minutes=24,seconds=47) / timedelta(minutes=30,seconds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch._higher_order_ops.foreach_map import foreach_map\n",
    "\n",
    "class TreeNode:\n",
    "    \"\"\"\n",
    "    A node in the decision tree.\n",
    "    \"\"\"\n",
    "    __slots__ = (\"is_leaf\", \"prediction\", \"feature_index\", \"threshold\", \"left\", \"right\", \"depth\")\n",
    "\n",
    "    def __init__(self, is_leaf=False, prediction=None, feature_index=None, threshold=None, left=None, right=None, depth=0):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.prediction = prediction\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "class DecisionTreeRegressorTorch:\n",
    "    \"\"\"\n",
    "    A regression decision tree implemented in PyTorch with iterative breadth-first build.\n",
    "\n",
    "    Splits nodes to minimize mean squared error (MSE).\n",
    "    Supports max_depth and a minimum impurity decrease threshold.\n",
    "    Uses PyTorch 2.7 torch._foreach_map for parallel split search at each depth.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_depth: int = 5, min_impurity_decrease: float = 1e-7):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.root = None\n",
    "\n",
    "    #@torch.compile\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Build the tree by iterating over depth levels.\n",
    "        \"\"\"\n",
    "        assert X.dim() == 2 and y.dim() == 1 and X.size(0) == y.size(0)\n",
    "\n",
    "        # Initialize root node\n",
    "        self.root = TreeNode()\n",
    "        # Track nodes, inputs, targets across depths\n",
    "        nodes = [self.root]\n",
    "        inputs = [X]\n",
    "        targets = [y]\n",
    "\n",
    "        for depth in range(self.max_depth):\n",
    "            next_nodes = []\n",
    "            next_inputs = []\n",
    "            next_targets = []\n",
    "\n",
    "            # Compute parent variances in parallel using foreach_map\n",
    "            \n",
    "            parent_vars = foreach_map(torch.var, targets, correction=0)\n",
    "            # Find best splits for all nodes at this depth in parallel\n",
    "            splits = foreach_map(self._find_best_split, inputs, targets, parent_vars)\n",
    "\n",
    "            for node, X_sub, y_sub, split in zip(nodes, inputs, targets, splits):\n",
    "                feature, threshold, imp_dec = split\n",
    "                n_samples = y_sub.numel()\n",
    "                node.depth = depth\n",
    "                # Stop splitting if no valid split, too few samples, or insufficient decrease\n",
    "                if feature is None or n_samples < 2 or imp_dec < self.min_impurity_decrease:\n",
    "                    node.is_leaf = True\n",
    "                    node.prediction = y_sub.mean().item()\n",
    "                else:\n",
    "                    node.is_leaf = False\n",
    "                    node.feature_index = feature\n",
    "                    node.threshold = threshold\n",
    "\n",
    "                    # Partition data\n",
    "                    mask = X_sub[:, feature] <= threshold\n",
    "                    X_left, y_left = X_sub[mask], y_sub[mask]\n",
    "                    X_right, y_right = X_sub[~mask], y_sub[~mask]\n",
    "\n",
    "                    node.left = TreeNode()\n",
    "                    node.right = TreeNode()\n",
    "\n",
    "                    # Queue children for next level\n",
    "                    next_nodes.extend([node.left, node.right])\n",
    "                    next_inputs.extend([X_left, X_right])\n",
    "                    next_targets.extend([y_left, y_right])\n",
    "\n",
    "            # Move to next depth\n",
    "            nodes, inputs, targets = next_nodes, next_inputs, next_targets\n",
    "            if len(nodes) == 0:\n",
    "                break\n",
    "\n",
    "        # Any remaining nodes become leaves\n",
    "        for node, y_sub in zip(nodes, targets):\n",
    "            node.is_leaf = True\n",
    "            node.prediction = y_sub.mean().item()\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict target values for input X.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            node = self.root\n",
    "            while not node.is_leaf:\n",
    "                node = node.left if x[node.feature_index] <= node.threshold else node.right\n",
    "            preds.append(node.prediction)\n",
    "        return torch.tensor(preds, dtype=X.dtype)\n",
    "\n",
    "    def _find_best_split(self, X: torch.Tensor, y: torch.Tensor, parent_variance: float):  # noqa: C901\n",
    "        \"\"\"\n",
    "        Vectorized single-node split search used by foreach_map.\n",
    "        Returns (feature_index, threshold, impurity_decrease).\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_samples < 2:\n",
    "            return None, None, 0.0\n",
    "\n",
    "        # Sort features and align targets\n",
    "        sorted_vals, sorted_idx = torch.sort(X, dim=0)\n",
    "        y_sorted = y[sorted_idx]\n",
    "\n",
    "        # Cumulative sums\n",
    "        csum_y = torch.cumsum(y_sorted, dim=0)\n",
    "        csum_y2 = torch.cumsum(y_sorted * y_sorted, dim=0)\n",
    "\n",
    "        # Split counts\n",
    "        left_counts = torch.arange(1, n_samples, device=X.device).unsqueeze(1).expand(n_samples-1, n_features)\n",
    "        right_counts = n_samples - left_counts\n",
    "\n",
    "        # Sums and sums of squares\n",
    "        left_sum = csum_y[:-1]\n",
    "        left_sum2 = csum_y2[:-1]\n",
    "        y_tot = y.sum()\n",
    "        y2_tot = (y * y).sum()\n",
    "        right_sum = y_tot - left_sum\n",
    "        right_sum2 = y2_tot - left_sum2\n",
    "\n",
    "        # Compute variances\n",
    "        left_var = left_sum2 / left_counts - (left_sum / left_counts) ** 2\n",
    "        right_var = right_sum2 / right_counts - (right_sum / right_counts) ** 2\n",
    "\n",
    "        # Weighted child variance\n",
    "        child_var = (left_counts * left_var + right_counts * right_var) / n_samples\n",
    "\n",
    "        # Impurity decrease\n",
    "        imp_dec = parent_variance - child_var\n",
    "        distinct = sorted_vals[:-1] != sorted_vals[1:]\n",
    "        imp_dec = imp_dec.masked_fill(~distinct, float('-inf'))\n",
    "\n",
    "        # Select best split\n",
    "        max_val, idx = imp_dec.reshape(-1).max(dim=0)\n",
    "        if max_val <= 0:\n",
    "            return None, None, 0.0\n",
    "\n",
    "        feat = idx % n_features\n",
    "        pos = idx // n_features\n",
    "        thresh = (sorted_vals[pos, feat] + sorted_vals[pos+1, feat]) / 2.0\n",
    "        return feat.item(), thresh.item(), max_val.item()\n",
    "\n",
    "    def get_leaf_nodes(self) -> list:\n",
    "        \"\"\"\n",
    "        Return all leaf nodes in the tree.\n",
    "        \"\"\"\n",
    "        leaves = []\n",
    "        stack = [self.root]\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            if node.is_leaf:\n",
    "                leaves.append(node)\n",
    "            else:\n",
    "                # push children to stack\n",
    "                if node.right is not None:\n",
    "                    stack.append(node.right)\n",
    "                if node.left is not None:\n",
    "                    stack.append(node.left)\n",
    "        return leaves\n",
    "\n",
    "    def get_leaves_sorted(self) -> list:\n",
    "        \"\"\"\n",
    "        Return leaf nodes sorted by their prediction values (ascending).\n",
    "        \"\"\"\n",
    "        leaves = self.get_leaf_nodes()\n",
    "        return sorted(leaves, key=lambda n: n.prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = torch.rand(1000, 30, device=\"cuda:0\")\n",
    "y = torch.rand(1000, device=\"cuda:0\")\n",
    "tree = DecisionTreeRegressorTorch(max_depth=1000000, min_impurity_decrease=1e-5)\n",
    "tree.fit(X, y)\n",
    "leaves = tree.get_leaves_sorted()\n",
    "\n",
    "len(leaves), np.max([n.depth for n in leaves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tensor/futures_individual/30m/GC-F10.pt: 100%|██████████| 86.0k/86.0k [00:00<00:00, 87.6kB/s]\n",
      "Downloading raw/futures_individual/30m/GC-F11.zip: 100%|██████████| 15.3k/15.3k [00:00<00:00, 28.5kB/s]\n",
      "Loading data from data/raw/futures_individual/30m/GC-F11.zip: 100%|██████████| 1629/1629 [00:00<00:00, 211579.02lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting datetime columns...\n",
      "Processing groups...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trade dates: 100%|██████████| 64/64 [00:00<00:00, 165.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing final calculations...\n",
      "Saving processed data...\n",
      "Processed data saved to data/processed/futures_individual/30m/GC-F11.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading processed/futures_individual/30m/GC-F11.zip: 100%|██████████| 30.2k/30.2k [00:00<00:00, 37.2kB/s]\n",
      "Loading data from data/processed/futures_individual/30m/GC-F11.zip: 100%|██████████| 2944/2944 [00:00<00:00, 315588.49lines/s]\n",
      "Uploading tensor/futures_individual/30m/GC-F11.pt: 100%|██████████| 107k/107k [00:00<00:00, 112kB/s]\n",
      "Downloading raw/futures_individual/30m/GC-F12.zip:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
     ]
    }
   ],
   "source": [
    "import ifera\n",
    "import torch\n",
    "from torch._higher_order_ops.foreach_map import foreach_map\n",
    "\n",
    "\n",
    "fm = ifera.FileManager()\n",
    "url = \"file:data/tensor/futures_rollover/30m/GC.pt\"\n",
    "fm.build_subgraph(url, ifera.RuleType.REFRESH)\n",
    "cm = ifera.ConfigManager()\n",
    "base_instrument = cm.get_base_instrument_config(\"GC\",\"30m\")\n",
    "base_tensor = torch.tensor([])\n",
    "contract_instruments = []\n",
    "contract_tensors = []\n",
    "\n",
    "get_params_time = 0\n",
    "get_tensor_time = 0\n",
    "\n",
    "for dep in fm.refresh_graph.successors(url):\n",
    "    fm.refresh_file(dep)\n",
    "    params = fm.get_node_params(ifera.RuleType.REFRESH, dep)\n",
    "\n",
    "    if params[\"type\"] == \"futures\":\n",
    "        base_tensor = ifera.load_data_tensor(\n",
    "            instrument=base_instrument,\n",
    "            reset=False,\n",
    "            dtype=torch.float32,\n",
    "            device=torch.device(\"cuda:0\"),\n",
    "            strip_date_time=False,\n",
    "        )\n",
    "    else:\n",
    "        contract_instrument = cm.create_derived_base_config(\n",
    "            base_instrument,\n",
    "            contract_code=params[\"contract_code\"],\n",
    "        )\n",
    "        contract_tensor = ifera.load_data_tensor(\n",
    "            instrument=contract_instrument,\n",
    "            reset=False,\n",
    "            dtype=torch.float32,\n",
    "            device=torch.device(\"cuda:0\"),\n",
    "            strip_date_time=False,\n",
    "        )\n",
    "        contract_tensors.append(contract_tensor)\n",
    "        contract_instruments.append(contract_instrument)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "agg_contract_tensor = torch.zeros(\n",
    "    (len(contract_tensors), base_tensor.shape[0], base_tensor.shape[1], base_tensor.shape[2]), \n",
    "    dtype=base_tensor.dtype,\n",
    "    device=base_tensor.device,\n",
    ")\n",
    "\n",
    "contract_tensors = sorted(contract_tensors, key=lambda x: (x[-1, 0, 2].to(torch.int64).item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_contract_tensors_to_agg(contract_tensors, base_tensor, agg_contract_tensor):\n",
    "    \"\"\"\n",
    "    Copies data from contract_tensors to agg_contract_tensor based on matching dates.\n",
    "    \n",
    "    Args:\n",
    "        contract_tensors (list): List of tensors, each shape (date_i, time, features)\n",
    "        base_tensor (torch.Tensor): Shape (date_base, time, features)\n",
    "        agg_contract_tensor (torch.Tensor): Shape (n, date_base, time, features)\n",
    "    \"\"\"\n",
    "    # Extract dates from base_tensor, shape (date_base,)\n",
    "    base_dates = base_tensor[:, 0, 2]\n",
    "    \n",
    "    # Compute matching indices for each contract_tensor\n",
    "    b_indices_list = []\n",
    "    for i in range(len(contract_tensors)):\n",
    "        # Extract dates, shape (date_i,)\n",
    "        contract_dates = contract_tensors[i][:, 0, 2]\n",
    "        # Broadcasting to find matches, shape (date_i, date_base)\n",
    "        matches = contract_dates[:, None] == base_dates[None, :]\n",
    "        # Get base indices, shape (date_i,)\n",
    "        b_indices = matches.long().argmax(dim=1)\n",
    "        b_indices_list.append(b_indices)\n",
    "    \n",
    "    # Concatenate all base indices, shape (total_dates,)\n",
    "    all_b_idx = torch.cat(b_indices_list, dim=0)\n",
    "    \n",
    "    # Create tensor of contract indices, shape (total_dates,)\n",
    "    all_i = torch.cat([\n",
    "        torch.full((contract_tensors[i].shape[0],), i, dtype=torch.long)\n",
    "        for i in range(len(contract_tensors))\n",
    "    ], dim=0)\n",
    "    \n",
    "    # Concatenate all contract data, shape (total_dates, time, features)\n",
    "    all_data = torch.cat(contract_tensors, dim=0)\n",
    "    \n",
    "    # Assign data to agg_contract_tensor in one operation\n",
    "    agg_contract_tensor[all_i, all_b_idx, :, :] = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_contract_tensors_to_agg(contract_tensors, base_tensor, agg_contract_tensor)\n",
    "agg_contract_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "agg_index = (agg_contract_tensor[0, :, 0, 2] == contract_tensors[0][21, 0, 2]).to(torch.int64).argmax()\n",
    "\n",
    "(agg_contract_tensor[:, :, 0, 2].count_nonzero(0) == 0).to(torch.int64).argmax()\n",
    "\n",
    "orddates = base_tensor[:, 0, 2].to(torch.int64).to(\"cpu\").numpy()\n",
    "dates = np.array([dt.date.fromordinal(int(x)) for x in orddates])\n",
    "weekends = np.array([dt.date.weekday(x) for x in dates]) >= 5\n",
    "weekends.sum()\n",
    "\n",
    "base_tensor[623, :, :]\n",
    "\n",
    "#TODO: Remove 0 volume dates (weekends)\n",
    "\n",
    "\n",
    "\n",
    "# Get the indices in dim=0 where agg_contract_tensor[:, 0, 0, 2] is not 0\n",
    "idx = agg_contract_tensor[:, 0, 0, 2].nonzero(as_tuple=True)[0]\n",
    "\n",
    "print(idx)\n",
    "\n",
    "print(np.array2string(base_tensor[0, 0, 4:].cpu().numpy(),\n",
    "    formatter={'float_kind': lambda x: f\"{x:.2f}\"}))\n",
    "    \n",
    "print(np.array2string(agg_contract_tensor[idx, 0, 0, 4:].cpu().numpy(),\n",
    "    formatter={'float_kind': lambda x: f\"{x:.2f}\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = base_tensor[:, :, 4:8].clone()\n",
    "agg_features = agg_contract_tensor[:, :, :, 4:8]\n",
    "\n",
    "base_features = torch.where(base_tensor[:, :, 8].unsqueeze(-1) == 0, torch.nan, base_features)\n",
    "\n",
    "matches = torch.all(\n",
    "        agg_features == base_features[None, :, :, :],\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "result = torch.full(\n",
    "    (base_tensor.shape[0], base_tensor.shape[1]),\n",
    "    float('nan'),\n",
    "    dtype=torch.float,\n",
    "    device=base_tensor.device\n",
    ")\n",
    "\n",
    "any_match = matches.any(dim=0)\n",
    "first_match_idx = matches.long().argmax(dim=0)\n",
    "result[any_match] = first_match_idx[any_match].float()\n",
    "\n",
    "\n",
    "d = 24\n",
    "t = 44\n",
    "\n",
    "print(result[d])\n",
    "print(np.array2string(result.nan_to_num(-1).max(dim=1)[0][0:200].to(torch.int64).cpu().numpy(), \n",
    "      formatter={'float_kind': lambda x: f\"{x:.2f}\"}))\n",
    "\n",
    "base_tensor[d, t, 4:9], agg_contract_tensor[0, d, t, 4:8], agg_contract_tensor[1, d, t, 4:8], agg_contract_tensor[2, d, t, 4:8], agg_contract_tensor[3, d, t, 4:8], agg_contract_tensor[14, d, t, 4:9], \\\n",
    "    dt.date.fromordinal(base_tensor[d, t, 2].to(torch.int64).item()),\\\n",
    "    dt.date.fromordinal(contract_tensors[0][-1, t, 2].to(torch.int64).item())\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
